---
title: "Final_Project"
author: "Billy Kwon and Yixuan Li"
date: "12/12/2021"
output: pdf_document
---

```{r data setup, include=FALSE}
# Load packages -----------------------------------------------------------
library(jsonlite)
library(dplyr)
library(ggplot2)
library(tidymodels)
library(stringr)
library(sentimentr)

# Parallelize
if (.Platform$OS.type == "windows") {
  doParallel::registerDoParallel(parallel::detectCores())
} else doMC::registerDoMC(parallel::detectCores())

# Clean and load data -----------------------------------------------------
# Data source from https://www.kaggle.com/datasnaek/youtube-new?select=USvideos.csv 

# TODO: Determine whether to use all countries or a subset. Currently set to just US for sake of speed while developing and tuning our models.
# countries <- c("CA", "DE", "FR", "GB", "IN", "JP", "KR", "MX", "RU", "US")
countries <- c("US")  

### Function to load data per country 
load_country_data <- function(countries) {
  df = data.frame()
  
  for (country in countries) {
    video <- read.csv(file = paste("archive/", country, "Videos.csv", sep=""))
    categories <- fromJSON(paste("archive/", country, "_category_id.json", sep=""), flatten = TRUE)
    categories <- categories[["items"]] 
    
    # merge video and category datasets and select columns
    categories <- categories %>% 
      rename(category_id = id, category_title = snippet.title) %>% 
      mutate(category_id = as.integer(category_id))
    video <- merge(x = video, y = categories, by = "category_id", all.x=TRUE) 
    country_df <- video %>% 
      mutate(comments_disabled = as.logical(comments_disabled)) %>%
      mutate(ratings_disabled = as.logical(ratings_disabled)) %>%
      mutate(video_error_or_removed = as.logical(video_error_or_removed)) %>%
      select(trending_date, views, likes, dislikes, comment_count, comments_disabled,
             ratings_disabled, video_error_or_removed, category_title, title, description, tags)
    
    # filter out duplicate trending videos, keep row from first time the video trends
    country_df <- country_df %>% group_by(title) %>% arrange(trending_date) %>% slice_head(n = 1) %>% ungroup() 

    df <- rbind(df, country_df)
  }
  
  df
}

all_videos_df <- load_country_data(countries = countries)
```


```{r data description}
summary(all_videos_df)
```

### Visualization

```{r counts of each category}
all_videos_df %>% group_by(category_title) %>% 
  summarize(counts = n()) %>%
  arrange(-counts) %>%                                
  mutate(category_title = factor(category_title, category_title)) %>%   
  ggplot(aes(x=category_title, y=counts, color=category_title)) + 
  geom_bar(stat="identity") +
  theme(axis.text.x = element_text(angle = 90)) +
  ggtitle("Trending Category Video Counts") + theme(plot.title = element_text(hjust = 0.5))
```


```{r plot views by categories}
all_videos_df %>% ggplot(aes(x=category_title, y=views, color=category_title)) + geom_point() +
    theme(axis.text.x = element_text(angle = 90)) +
    ggtitle("Trending Category Video Views") + theme(plot.title = element_text(hjust = 0.5))
```

```{r plot comments by categories}
all_videos_df %>% ggplot(aes(x=category_title, y=comment_count, color=category_title)) +
  geom_point() + theme(axis.text.x = element_text(angle = 90)) + 
  ggtitle("Trending Category Video Comment Count") + theme(plot.title = element_text(hjust = 0.5))

```

```{r plot comments v.s. views}
all_videos_df %>% ggplot(aes(x=views, y=comment_count, color=category_title)) +
  geom_point() + theme(axis.text.x = element_text(angle = 90)) +
  ggtitle("Trending Views vs Comment Counts per Category") + theme(plot.title = element_text(hjust = 0.5))
```

### Analysis Part One - Raw Data
The first analysis seeks to create a model to classify trending youtube videos into their corresponding Youtube category based on the raw data. 

```{r Analysis Part One - Random Forest}
set.seed(20211213) 
# Split data into 80/20, training and testing respectively
all_split <- initial_split(all_videos_df, prob = 0.8, strata = category_title)
all_train <- training(all_split)
all_test <- testing(all_split)

# Perform pre processing
training <- all_train %>% mutate(category_title = as.ordered(category_title))
testing <- all_test %>% mutate(category_title = as.ordered(category_title))

# Basic recipe
base_recipe <- 
  recipe(category_title ~ views + likes + dislikes + comment_count +
           comments_disabled + ratings_disabled + video_error_or_removed,
         data = training) %>% 
  step_nzv(all_numeric_predictors()) %>%
  step_center(all_numeric_predictors()) %>% 
  step_scale(all_numeric_predictors()) %>%
  prep()

# Random forest
rf_model <- rand_forest() %>%
  set_engine("randomForest",
             num.threads = parallel::detectCores(), 
             importance = TRUE, 
             verbose = TRUE) %>% 
  set_mode("classification") %>% 
  set_args(trees = 1500)

rf_wf <- workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(base_recipe)

rf_fit <- fit(rf_wf, training)
conf_mat_results <- bind_cols(testing,
          predict(rf_fit, new_data = testing)) %>%
  conf_mat(truth = category_title, estimate = .pred_class)

conf_mat_results
summary(conf_mat_results)
```
## Tune Random Forest Parameters to view and quantify improvements
```{r Analysis Part One Tuned Parameters Random Forest}
set.seed(20211213) 
# Tune Random Forest Parameters: mtry and min_n 
# mtry = number of predictors that will be randomly sampled at each split when creating tree models
# min_n = minimum number of data points in node required for node to be split further

rf_model_tune <- rand_forest(mtry = tune(), min_n = tune()) %>%
  set_engine("randomForest",
             num.threads = parallel::detectCores(), 
             importance = TRUE, 
             verbose = TRUE) %>% 
  set_mode("classification") %>% 
  set_args(trees = 1000)

trees_folds <- vfold_cv(training)

tune_recipe <- base_recipe

rf_tuned_wf <- workflow() %>% 
  add_model(rf_model_tune) %>% 
  add_recipe(tune_recipe)

tuned_results <- tune_grid(rf_tuned_wf, resamples = trees_folds, grid = 10)

most_accurate <- 
  tuned_results %>% 
  select_best("accuracy")

most_accurate

final_tuned_wf <- finalize_workflow(rf_tuned_wf, most_accurate)

rf_tuned_fit <- fit(final_tuned_wf, training)
conf_mat_tuned_results <- bind_cols(testing,
          predict(rf_tuned_fit, new_data = testing)) %>%
  conf_mat(truth = category_title, estimate = .pred_class)

conf_mat_tuned_results
summary(conf_mat_tuned_results)
```

### Analysis Part Two - Reduce number of categories 
In the first analysis, we classified the videos into 44 specific categories; perhaps, we can reduce the number of categories from 44 specific categories to 4 broader, more encompassing categories and examine if we can obtain a better result.

```{r Analysis Part Two}
set.seed(20211213)
# Reduce categories into 4 broader categories
all_videos_broad_df <- all_videos_df %>% 
  mutate(broad_category = case_when(category_title %in% c("Sports", "Travel & Events", "People & Blogs", "Autos & Vehicles",
                                                          "Gaming", "Pets & Animals", "Videoblogging") ~ "Activities", 
                                    category_title %in%  c("Entertainment") ~ "Entertainment", 
                                    category_title %in% c("Comedy", "Movies", "Film & Animation", "Shows",
                                                          "Trailers", "Music") ~ "Film & TV", 
                                    TRUE ~ "Other")) 
all_videos_broad_df %>% count(broad_category)

# Split data into 80/20, training and testing respectively
broad_split <- initial_split(all_videos_broad_df, prob = 0.8, strata = broad_category)
broad_train <- training(broad_split)
broad_test <- testing(broad_split)

# Perform pre processing
training_br <- broad_train %>% mutate(broad_category = as.ordered(broad_category))
testing_br <- broad_test %>% mutate(broad_category = as.ordered(broad_category))

# recipe for broader categories
broad_recipe <- 
  recipe(broad_category ~ views + likes + dislikes + comment_count +
           comments_disabled + ratings_disabled + video_error_or_removed,
         data = training_br) %>% 
  step_nzv(all_numeric_predictors()) %>%
  step_center(all_numeric_predictors()) %>% 
  step_scale(all_numeric_predictors()) %>%
  prep()

rf_model_br <- rand_forest() %>%
  set_engine("randomForest",
             num.threads = parallel::detectCores(), 
             importance = TRUE, 
             verbose = TRUE) %>% 
  set_mode("classification") %>% 
  set_args(trees = 1500)

rf_wf_br <- workflow() %>% 
  add_model(rf_model_br) %>% 
  add_recipe(broad_recipe)

rf_fit_br <- fit(rf_wf_br, training_br)
conf_mat_results_br <- bind_cols(testing_br,
          predict(rf_fit_br, new_data = testing_br)) %>%
  conf_mat(truth = broad_category, estimate = .pred_class)

conf_mat_results_br
summary(conf_mat_results_br)
```
## Tune Random Forest Parameters to view and quantify improvements
Again, we will tune the random forest parameters, mtry and min_n, to quantify how much of an improvement we can obtain.
```{r Analysis Part Two Tuned parameters}
set.seed(20211213)
# Tune Random Forest Parameters: mtry and min_n 

rf_model_tune_br <- rand_forest(mtry = tune(), min_n = tune()) %>%
  set_engine("randomForest",
             num.threads = parallel::detectCores(), 
             importance = TRUE, 
             verbose = TRUE) %>% 
  set_mode("classification")  %>% 
  set_args(trees = 1000)

trees_folds_br <- vfold_cv(training_br)

tune_recipe_br <- broad_recipe

rf_tuned_wf_br <- workflow() %>% 
  add_model(rf_model_tune_br) %>% 
  add_recipe(tune_recipe_br)

tuned_results_br <- tune_grid(rf_tuned_wf_br, resamples = trees_folds_br, grid = 10)

most_accurate_br <- 
  tuned_results_br %>% 
  select_best("accuracy")

most_accurate

final_tuned_wf_br <- finalize_workflow(rf_tuned_wf_br, most_accurate_br)

rf_tuned_fit_br <- fit(final_tuned_wf_br, training_br)
conf_mat_tuned_results_br <- bind_cols(testing_br,
          predict(rf_tuned_fit_br, new_data = testing_br)) %>%
  conf_mat(truth = broad_category, estimate = .pred_class)

conf_mat_tuned_results_br
summary(conf_mat_tuned_results_br)
```

### Analysis Part Three - Feature Engineering
The third analysis builds on the first analysis by adding more engineered features and determining the impact these features have on the model itself. 

## Assign sentiment scores to description 
```{r Analysis Part Three Sentiment}
# Encoding/ pre processing text
all_videos_sentiment_df <- mutate(all_videos_broad_df,
                                  description = iconv(description, from = "UTF-8", to = "ASCII//TRANSLIT", 
                                                      sub = "byte"), 
                                  description = tolower(description), 
                                  description = str_remove_all(description, pattern = "[[:punct:]]+"), # Remove punctuation 
                                  description = str_remove_all(description, pattern = "(#|@)[[:word:]]+"), # Remove words starting w @ or #
                                  description = str_remove_all(description, pattern = "(<[[:alnum:]]+>)+") # Remove all text between < > 
                                  )

# Get sentimejts for each description - Note - runs super slow for large DF
avg_description_sentiments <- all_videos_sentiment_df %>% 
  select(description) %>%
  get_sentences() %>%
  sentiment_by()

all_videos_with_description_sentiment <- bind_cols(all_videos_broad_df, avg_description_sentiments)
```

## Explore and Visualize Sentiments
Detour to examine what the sentiments look like across these tweets and if there are any trends we can identify before we use this as an additional feature. 

Plot word count vs sentiment scores
```{r Sentiment word count vs sentiment score}
all_videos_with_description_sentiment %>%
  ggplot(aes(x=word_count, y=ave_sentiment, color=broad_category)) +
  geom_point() + theme(axis.text.x = element_text(angle = 90)) + 
  ggtitle("Trending Category Video Word Count vs Sentiment") + theme(plot.title = element_text(hjust = 0.5))
```

Determine most positive and negative tweet
```{r Most positive and negative tweet}
most_positive_tweet_row <- which.max(all_videos_with_description_sentiment$ave_sentiment)

most_negative_tweet_row <- which.min(all_videos_with_description_sentiment$ave_sentiment)

all_videos_with_description_sentiment %>% 
  filter(row_number() == most_positive_tweet_row) %>%
  select(title, description, ave_sentiment)

all_videos_with_description_sentiment %>% 
  filter(row_number() == most_negative_tweet_row) %>%
  select(title, description, ave_sentiment)
```

Visualizing the sentiment scores vs word counts across the broad categories reveals no discernible pattern. Perhaps, we can try plotting the densities to reveal more latent patterns.
```{r Sentiment density plot by category}
all_videos_with_description_sentiment %>% 
  ggplot(aes(x = ave_sentiment, y = ..density..)) +
  geom_histogram(bins = 20) +
  facet_wrap(~broad_category) + 
  ggtitle("Trending Category Video Sentiment Scores Density by Category") + theme(plot.title = element_text(hjust = 0.5))
```
Again, the plot does not seem to tell us how the sentiment provides any additional information to a specific broad category. Nonetheless, we will try to utilize the sentiment scores as an extra feature and determine how well it improves or worsens our model in the next step. 

## Build Tuned Random Forest Modelwith Sentiment Scores for Broad Categories
```{r Tuned Random Forest Broad Categories}
set.seed(20211213)
# Split data into 80/20, training and testing respectively
sentiment_split <- initial_split(all_videos_with_description_sentiment, prob = 0.8, strata = broad_category)
sentiment_train <- training(sentiment_split)
sentiment_test <- testing(sentiment_split)

# Perform pre processing
sentiment_training <- sentiment_train %>% mutate(broad_category = as.ordered(broad_category))
sentiment_testing <- sentiment_test %>% mutate(broad_category = as.ordered(broad_category))

# Recipe for broad categories with sentiment 
sentiment_recipe <- 
  recipe(broad_category ~ views + likes + dislikes + comment_count +
           comments_disabled + ratings_disabled + video_error_or_removed + ave_sentiment,
         data = sentiment_training) %>% 
  step_nzv(all_numeric_predictors()) %>%
  step_center(all_numeric_predictors()) %>% 
  step_scale(all_numeric_predictors()) %>%
  prep()

sentiment_rf_model <- rand_forest(mtry = tune(), min_n = tune()) %>%
  set_engine("randomForest",
             num.threads = parallel::detectCores(), 
             importance = TRUE, 
             verbose = TRUE) %>% 
  set_mode("classification") %>% 
  set_args(trees = 1500)

sentiment_trees_folds_br <- vfold_cv(sentiment_training)

sentiment_rf_wf <- workflow() %>% 
  add_model(sentiment_rf_model) %>% 
  add_recipe(sentiment_recipe)

sentiment_tuned_results <- tune_grid(sentiment_rf_wf, resamples = sentiment_trees_folds_br, grid = 10)

sentiment_most_accurate <- 
  sentiment_tuned_results %>% 
  select_best("accuracy")

sentiment_final_wf_br <- finalize_workflow(sentiment_rf_wf, sentiment_most_accurate)

sentiment_rf_fit <- fit(sentiment_final_wf_br, sentiment_training)
sentiment_conf_mat_results <- bind_cols(sentiment_testing,
          predict(sentiment_rf_fit, new_data = sentiment_testing)) %>%
  conf_mat(truth = broad_category, estimate = .pred_class)

sentiment_conf_mat_results
summary(sentiment_conf_mat_results)
```


